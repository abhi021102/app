{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIf6j8NxR33Nne2QMQvybv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhi021102/app/blob/master/FM_crashes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Md9AeuuQasmP"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Peak finding in times series\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def peak_finding(data,window_size):\n",
        "    \"\"\"\n",
        "    find values and positions of peaks in a given time series data.\n",
        "    return a list of tuples [(x1, max1), (x2, max2),..,(xn, maxn)]\n",
        "\n",
        "    data :       a given time series data\n",
        "    window_size: look for peaks in a box of \"window_size\" size\n",
        "\n",
        "    \"\"\"\n",
        "    data_extended = np.concatenate([np.zeros(window_size),data,np.zeros(window_size)])\n",
        "    max_list = []\n",
        "\n",
        "    for i,value in enumerate(data_extended):\n",
        "        if (i >= window_size) and (i < len(data_extended)-window_size):\n",
        "            try:\n",
        "                max_left = data_extended[(i-window_size):i+1].max()\n",
        "                max_right = data_extended[i:(i+window_size)+1].max()\n",
        "                chek_value = data_extended[i] - ((max_left+max_right)/2)\n",
        "            except ValueError:\n",
        "                 pass\n",
        "\n",
        "            if (chek_value >=0):\n",
        "                max_list.append((i-window_size,data[(i-window_size)]))\n",
        "    return max_list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Peak finding in times series\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def peak_finding(data,window_size):\n",
        "    \"\"\"\n",
        "    find values and positions of peaks in a given time series data.\n",
        "    return a list of tuples [(x1, max1), (x2, max2),..,(xn, maxn)]\n",
        "\n",
        "    data :       a given time series data\n",
        "    window_size: look for peaks in a box of \"window_size\" size\n",
        "\n",
        "    \"\"\"\n",
        "    data_extended = np.concatenate([np.zeros(window_size),data,np.zeros(window_size)])\n",
        "    max_list = []\n",
        "\n",
        "    for i,value in enumerate(data_extended):\n",
        "        if (i >= window_size) and (i < len(data_extended)-window_size):\n",
        "            try:\n",
        "                max_left = data_extended[(i-window_size):i+1].max()\n",
        "                max_right = data_extended[i:(i+window_size)+1].max()\n",
        "                chek_value = data_extended[i] - ((max_left+max_right)/2)\n",
        "            except ValueError:\n",
        "                 pass\n",
        "\n",
        "            if (chek_value >=0):\n",
        "                max_list.append((i-window_size,data[(i-window_size)]))\n",
        "    return max_list\n",
        "\n",
        "import pandas as pd\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random as rand\n",
        "#import peak_finding as pf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "#from peak_finding import peak_finding\n",
        "\n",
        "\n",
        "\n",
        "# function to evaluate LPPL\n",
        "def LPPL(t, A, B, tc, m, C, omega, phi):\n",
        "    lppl_val = A + B*((tc-t)**m)*(1 + C*(np.cos(omega * np.log(tc-t) + phi)))\n",
        "    return lppl_val;\n",
        "\n",
        "\n",
        "# function to calculate RMSE\n",
        "def error_function(A, B, tc, m, C, omega, phi):\n",
        "    observed_values = np.log(y_train)\n",
        "    predicted_values = LPPL(X_train, A, B, tc, m, C, omega, phi)\n",
        "    diff_sqr = (predicted_values - observed_values)**2\n",
        "    total = np.sum(diff_sqr)\n",
        "    total = total/len(observed_values)\n",
        "    rmse = math.sqrt(total)\n",
        "    return rmse\n",
        "\n",
        "\n",
        "def objective_function(params):\n",
        "    return error_function(params[0],params[1],params[2],params[3],params[4],params[5],params[6])\n",
        "\n",
        "\n",
        "\n",
        "# DE function\n",
        "def DE(objf,lb,ub,dim,PopSize,iters):\n",
        "\n",
        "    mutation_factor=0.5\n",
        "    crossover_ratio=0.7\n",
        "    stopping_func=None\n",
        "\n",
        "    # convert lb, ub to array\n",
        "    if not isinstance(lb, list):\n",
        "        lb = [lb for _ in range(dim)]\n",
        "        ub = [ub for _ in range(dim)]\n",
        "\n",
        "    best = float(\"inf\")\n",
        "    leader_solution = []\n",
        "    # initialize population\n",
        "    population = []\n",
        "\n",
        "    population_fitness = np.array([float(\"inf\") for _ in range(PopSize)])\n",
        "\n",
        "    for p in range(PopSize):\n",
        "        sol = []\n",
        "        for d in range(dim):\n",
        "            d_val = rand.uniform(lb[d], ub[d])\n",
        "            sol.append(d_val)\n",
        "\n",
        "        population.append(sol)\n",
        "\n",
        "    population = np.array(population)\n",
        "\n",
        "    # calculate fitness for all the population\n",
        "    for i in range(PopSize):\n",
        "        fitness = objf(population[i, :])\n",
        "        population_fitness[p] = fitness\n",
        "        #s.func_evals += 1\n",
        "\n",
        "        # is leader ?\n",
        "        if fitness < best:\n",
        "            best = fitness\n",
        "            leader_solution = population[i, :]\n",
        "\n",
        "    convergence_curve=np.zeros(iters)\n",
        "\n",
        "    t = 0\n",
        "    while t < iters:\n",
        "        # should i stop\n",
        "        if stopping_func is not None and stopping_func(best, leader_solution, t):\n",
        "            break\n",
        "\n",
        "        # loop through population\n",
        "        for i in range(PopSize):\n",
        "            # 1. Mutation\n",
        "\n",
        "            # select 3 random solution except current solution\n",
        "            ids_except_current = [_ for _ in  range(PopSize) if _ != i]\n",
        "            id_1, id_2, id_3 = rand.sample(ids_except_current, 3)\n",
        "\n",
        "            mutant_sol = []\n",
        "            for d in range(dim):\n",
        "                d_val = population[id_1, d] + mutation_factor * (population[id_2, d] - population[id_3, d])\n",
        "\n",
        "                # 2. Recombination\n",
        "                rn = rand.uniform(0, 1)\n",
        "                if rn > crossover_ratio:\n",
        "                    d_val = population[i, d]\n",
        "\n",
        "                # add dimension value to the mutant solution\n",
        "                mutant_sol.append(d_val)\n",
        "\n",
        "            # 3. Replacement / Evaluation\n",
        "\n",
        "            # clip new solution (mutant)\n",
        "            mutant_sol = np.clip(mutant_sol, lb, ub)\n",
        "\n",
        "            # calc fitness\n",
        "            mutant_fitness = objf(mutant_sol)\n",
        "            #s.func_evals += 1\n",
        "\n",
        "            # replace if mutant_fitness is better\n",
        "            if mutant_fitness < population_fitness[i]:\n",
        "                population[i, :] = mutant_sol\n",
        "                population_fitness[i] = mutant_fitness\n",
        "\n",
        "                # update leader\n",
        "                if mutant_fitness < best:\n",
        "                    best = mutant_fitness\n",
        "                    leader_solution = mutant_sol\n",
        "\n",
        "        convergence_curve[t]=best\n",
        "        if (t%1==0):\n",
        "               print(['At iteration '+ str(t+1)+ ' the best fitness is '+ str(best)]);\n",
        "\n",
        "        # increase iterations\n",
        "        t = t + 1\n",
        "\n",
        "    # return solution\n",
        "    return leader_solution, best\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "    Implementation of LPPL for crash prediction\n",
        "\n",
        "'''\n",
        "\n",
        "# linear regression for determining initial values of A, B\n",
        "\n",
        "def A_B_initial_values(ind_var, dep_var):\n",
        "    ind_var = ind_var.reshape(-1, 1)\n",
        "    regressor = LinearRegression()\n",
        "    regressor.fit(ind_var, dep_var)\n",
        "    param_A = regressor.intercept_\n",
        "    param_B = regressor.coef_[0]\n",
        "    return param_A, param_B\n",
        "\n",
        "\n",
        "# this function returns array of initial values of all params using peak finding and above A_B_initial_values function\n",
        "\n",
        "def tc_omega_phi_initial_values(window_size):\n",
        "    #finding peaks for the given window size\n",
        "\n",
        "    peaks_arr = peak_finding(y_train, window_size)\n",
        "    x_peaks = [ x+1 for x,y in peaks_arr ]\n",
        "\n",
        "\n",
        "#calculation of initial values of parameters\n",
        "\n",
        "    init_all_params_arr = []\n",
        "\n",
        "    peaks_arr_len = len(peaks_arr)\n",
        "    for i in range(0, peaks_arr_len-2):\n",
        "        j = i+1\n",
        "        k = i+2\n",
        "        pi = x_peaks[i]\n",
        "        pj = x_peaks[j]\n",
        "        pk = x_peaks[k]\n",
        "        temp_ro = (pj-pi)/(pk-pj)\n",
        "        if (temp_ro <= 1):\n",
        "            continue;\n",
        "        param_tc = (temp_ro*pk - pj)/(temp_ro - 1)\n",
        "        param_omega = (2 * math.pi)/(np.log(temp_ro))\n",
        "        if (param_tc <= pk or param_tc <= X_train[len(X_train)-1]):\n",
        "            continue;\n",
        "        param_phi = math.pi - param_omega * np.log(param_tc - pk)\n",
        "        param_m = 1 # this is beta\n",
        "        param_C = 0\n",
        "        ind_var_arr = param_tc - X_train\n",
        "        param_A, param_B = A_B_initial_values(ind_var_arr, y_train_log)\n",
        "\n",
        "\n",
        "        print(\"A: \",param_A,\" B: \",param_B,\" tc: \",param_tc,\" m: \",param_m,\" C: \",param_C,\" omega: \",param_omega,\" phi: \",param_phi)\n",
        "        init_all_params_arr.append([param_A, param_B, param_tc, param_m, param_C, param_omega, param_phi])\n",
        "\n",
        "    return init_all_params_arr\n",
        "\n",
        "\n",
        "\n",
        "col_list = ['time', 'Open']\n",
        "datadf = pd.read_csv(r\"/content/NIFTY 50.csv\", usecols = col_list)\n",
        "\n",
        "X = datadf['time'].to_numpy()\n",
        "y = datadf['Open'].to_numpy()\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle = False)\n",
        "y_train_log = np.log(y_train)\n",
        "\n",
        "\n",
        "# try with several window sizes\n",
        "\n",
        "\n",
        "# loops through several window sizes and note rmse and tc\n",
        "initial_window_size = 10\n",
        "len_x = len(X_train)\n",
        "\n",
        "tc_rmse_arr_for_window = []\n",
        "rmse_tc_arr = []\n",
        "\n",
        "\n",
        "for ws in range(initial_window_size, len_x, 2):\n",
        "    dim = 7\n",
        "    window_size = ws\n",
        "    params = tc_omega_phi_initial_values(window_size)\n",
        "    min_rmse_for_this_window = 999999999.99\n",
        "    corresponding_tc = 0\n",
        "    for i in range(0, len(params)):\n",
        "        param_lower_bound = params[0]\n",
        "        param_upper_bound = [0]*7\n",
        "        param_upper_bound[0] = 2 * abs(param_lower_bound[0])    # A\n",
        "        param_upper_bound[1] = max(2 * abs(param_lower_bound[1]), 2)    # B\n",
        "        param_upper_bound[2] = abs(param_lower_bound[2]) + 300    # tc\n",
        "        param_upper_bound[3] = 2    # m or beta\n",
        "        param_upper_bound[4] = 1    # C\n",
        "        param_upper_bound[5] = 2 * abs(param_lower_bound[5])    # omega\n",
        "        param_upper_bound[6] = 2*math.pi    # phi\n",
        "        # using DE for optimizing the parameters and fitting the LPPL\n",
        "        opt_params, rmse = DE(objective_function, param_lower_bound, param_upper_bound, dim, 70, 100)\n",
        "        rmse_tc_arr.append([opt_params[2], rmse])\n",
        "        if rmse < min_rmse_for_this_window:\n",
        "            min_rmse_for_this_window = rmse\n",
        "            corresponding_tc = opt_params[2]\n",
        "    print(\"Window size: \",window_size, \" Param sets: \", len(params), \" Minimum rmse: \",min_rmse_for_this_window)\n",
        "    print(\"------------------------------------------------------------------------\")\n",
        "    if len(params) > 0:\n",
        "        tc_rmse_arr_for_window.append([window_size, min_rmse_for_this_window, corresponding_tc])\n",
        "\n",
        "\n",
        "rmse_tc_df = pd.DataFrame(rmse_tc_arr)\n",
        "tc_rmse_window_df = pd.DataFrame(tc_rmse_arr_for_window)\n",
        "\n",
        "\n",
        "\n",
        "rmse_tc_df.to_csv(r\"doc1.csv\")\n",
        "tc_rmse_window_df.to_csv(r\"doc2.csv\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Following section is for plotting the relevant data as part of the requirements for report\n",
        "'''\n",
        "# plot for tc and closing price. The best value of tc is taken from the csv file created above\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(y)\n",
        "plt.title(\"Closing price index and critical time\")\n",
        "plt.xlabel(\"Days\")\n",
        "plt.ylabel(\"Closing price\")\n",
        "plt.axvline(x=428.229449337481, color='r') # tc value taken from resulting file\n",
        "plt.show()\n",
        "\n",
        "# plot of training data\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(y_train)\n",
        "plt.title(\"Closing price index\")\n",
        "plt.xlabel(\"Days\")\n",
        "plt.ylabel(\"Closing price\")\n",
        "\n",
        "# plot of whole data\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(y)\n",
        "plt.title(\"Closing price index\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "RcZObKpHa8Wq",
        "outputId": "a323e873-830d-495a-dbe4-76f0f23f9514"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Usecols do not match columns, columns expected but not found: ['Open']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-b8a6f77a3408>\u001b[0m in \u001b[0;36m<cell line: 226>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0mcol_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m \u001b[0mdatadf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"/content/NIFTY 50.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatadf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             ):\n\u001b[0;32m--> 140\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_usecols_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# error: Cannot determine type of 'names'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_validate_usecols_names\u001b[0;34m(self, usecols, names)\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musecols\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    980\u001b[0m                 \u001b[0;34mf\"Usecols do not match columns, columns expected but not found: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;34mf\"{missing}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Usecols do not match columns, columns expected but not found: ['Open']"
          ]
        }
      ]
    }
  ]
}